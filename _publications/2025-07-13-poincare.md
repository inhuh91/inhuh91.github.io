---
title: "Context-Informed Neural ODEs Unexpectedly Identify Broken Symmetries: Insights from the Poincaré-Hopf Theorem"
collection: publications
category: conferences
permalink: /publication/poincare
excerpt: '<strong>In Huh</strong>, Changwook Jeong, Muhammad Ashraful Alam'
date: 2025-07-13
venue: 'International Conference on Machine Learning (<strong>ICML</strong>)'
paperurl: 'https://icml.cc/virtual/2025/poster/45590'
summary: '<strong>In Huh</strong> et al., <i>International Conference on Machine Learning (<strong>ICML</strong>)</i>, 2025.'
header:
  teaser: poincare.png
---
<p align="justify">
Out-Of-Domain (OOD) generalization is a significant challenge in learning dynamical systems, especially when they exhibit bifurcation, a sudden topological transition triggered by a model parameter crossing a critical threshold. A prevailing belief is that machine learning models, unless equipped with strong priors, struggle to generalize across bifurcations due to the abrupt changes in data characteristics. Contrary to this belief, we demonstrate that context-dependent Neural Ordinary Differential Equations (NODEs), trained solely on localized, pre-bifurcation, symmetric data and without physics-based priors, can still identify post-bifurcation, symmetry-breaking behaviors, even in a zero-shot manner. We interpret this capability to the model's implicit utilization of topological invariants, particularly the Poincaré index, and offer a formal explanation based on the Poincaré-Hopf theorem. We derive the conditions under which NODEs can recover—or erroneously hallucinate—broken symmetries without explicit training. Building on this insight, we showcase a topological regularizer inspired by the Poincaré-Hopf theorem and validate it empirically on phase transitions of systems described by the Landau–Khalatnikov equation.
</p>
<hr>

<strong>In Huh</strong> et al., <i>International Conference on Machine Learning (<strong>ICML</strong>)</i>, 2025.

[Download Paper](https://icml.cc/virtual/2025/poster/45590)